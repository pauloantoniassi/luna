import {ChatCompletionMessageParam} from "openai/resources";
import {LlmService} from "../services/llm.service";
import { Data } from "../utils/database";
import PERSONALITY_PROMPT from "../constants/PERSONALITY_PROMPT";
import * as fs from "fs";
import path from "path";
import getProjectRootDir from "../utils/getProjectRootDir";
import beautifulLogger from "../utils/beautifulLogger";
import {AIChatResponseType, AIChatResponseZod} from "../models/ai-action.dto";

export type Message = {
  content: string;
  name: string | undefined;
  ia: boolean;
  jid: string;
}[];

const stickersDir = path.join(getProjectRootDir(), "assets", "stickers");
if (!fs.existsSync(stickersDir))
  throw new Error("Diret√≥rio de stickers n√£o encontrado: " + stickersDir);
const stickerOptions: string[] = fs
  .readdirSync(stickersDir)
  .filter((file) => file.endsWith(".webp"));

const audiosDir = path.join(getProjectRootDir(), "assets", "audios");
if (!fs.existsSync(audiosDir)) throw new Error("Diret√≥rio de √°udios n√£o encontrado: " + audiosDir);
const audioOptions: string[] = fs.readdirSync(audiosDir).filter((file) => file.endsWith(".mp3"));

const memesDir = path.join(getProjectRootDir(), "assets", "memes");
if (!fs.existsSync(memesDir)) throw new Error("Diret√≥rio de memes n√£o encontrado: " + memesDir);
const memeOptions: string[] = fs.readdirSync(memesDir).filter((file) => file.endsWith(".jpg"));

export default async function generateResponse(
  data: Data,
  messages: Message
): Promise<AIChatResponseType> {
  beautifulLogger.aiGeneration("start", "Iniciando gera√ß√£o de resposta...");
  const AI_MODEL = process.env.AI_MODEL;
  // TODO: Use getConfig

  if(!AI_MODEL) {
    beautifulLogger.aiGeneration("error", "Vari√°vel de ambiente AI_MODEL n√£o est√° definida");
    throw new Error("Vari√°vel de ambiente AI_MODEL n√£o est√° definida");
  }

  const uniqueMessages = messages.filter((message, index, array) => {
    return !array.some(
      (otherMessage, otherIndex) =>
        otherIndex > index &&
        otherMessage.content === message.content &&
        otherMessage.name === message.name
    );
  });

  const messagesMapped: string = uniqueMessages
    .map((message, i) => `${i + 1} - ${message.content}`)
    .join("\n");

  beautifulLogger.aiGeneration("processing", {
    "mensagens processadas": uniqueMessages.length,
    "mensagens originais": messages.length,
    "duplicatas removidas": messages.length - uniqueMessages.length,
    "mensagem mais recente": uniqueMessages[uniqueMessages.length - 1]?.content || "nenhuma",
  });

  const formatDataForPrompt = (data: Data): string => {
    let formattedData = "Resumo da conversa e opini√µes dos usu√°rios:\n\n";

    if (data.summary) {
      formattedData += `üìã RESUMO DA CONVERSA:\n${data.summary}\n\n`;
    }

    if (data.opinions && data.opinions.length > 0) {
      formattedData += `üë• OPIN√ïES SOBRE OS USU√ÅRIOS:\n`;
      data.opinions.forEach((opinion) => {
        formattedData += `‚Ä¢ ${opinion.name} (${opinion.jid}):\n`;

        let opnion = "NEUTRO/MISTO";
        if (opinion.opinion < 20) opnion = "ODEIO ELE";
        else if (opinion.opinion < 40) opnion = "N√ÉO GOSTO";
        else if (opinion.opinion < 60) opnion = "NEUTRO/MISTO";
        else if (opinion.opinion < 80) opnion = "GOSTO BASTANTE";
        else if (opinion.opinion <= 100) opnion = "APAIXONADA";

        formattedData += `  - N√≠vel de opini√£o: ${opinion.opinion}/100 (${opnion})\n`;
        if (opinion.traits && opinion.traits.length > 0) {
          formattedData += `  - O que acho dele (Caracter√≠sticas): ${opinion.traits.join(", ")}\n`;
        }
        formattedData += "\n";
      });
    }

    return formattedData.trim();
  };

  const contextData = formatDataForPrompt(data);

  const inputMessages: ChatCompletionMessageParam[] = [
    { role: "system", content: PERSONALITY_PROMPT },
    { role: "assistant", content: contextData },
    {
      role: "user",
      content: `Conversa: \n\n${messagesMapped}`,
    },
  ];

  const responseSchema = {
      name: "bot_response",
      strict: false,
    // TODO: Copy the description to Zod schema and then reuse the zod schema here
      schema: {
        type: "object",
        properties: {
          actions: {
            type: "array",
            minItems: 1,
            items: {
              type: "object",
              properties: {
                type: {
                  type: "string",
                  enum: ["message", "sticker", "audio", "poll", "location", "meme", "contact"],
                  description: "Tipo da a√ß√£o",
                },
                message: {
                  type: "object",
                  properties: {
                    reply: {
                      type: "string",
                      description: "ID da mensagem que est√° sendo respondida (opcional - apenas se n√£o estiver respondendo a mais recente)",
                    },
                    text: {
                      type: "string",
                      description:
                        "Resposta com personalidade passivo-agressiva/ir√¥nica (m√°ximo 300 caracteres)",
                    },
                  },
                  required: ["text"],
                  additionalProperties: false,
                },
                sticker: {
                  type: "string",
                  enum: stickerOptions,
                  description: "Nome do arquivo de sticker da lista dispon√≠vel",
                },
                audio: {
                  type: "string",
                  enum: audioOptions,
                  description: "Nome do arquivo de √°udio da lista dispon√≠vel",
                },
                meme: {
                  type: "string",
                  enum: memeOptions,
                  description: "Nome do arquivo de meme da lista dispon√≠vel",
                },
                poll: {
                  type: "object",
                  properties: {
                    question: {
                      type: "string",
                      description: "Pergunta ir√¥nica/engra√ßada para a enquete",
                    },
                    options: {
                      type: "array",
                      items: {
                        type: "string",
                      },
                      minItems: 2,
                      maxItems: 3,
                      description: "2 a 3 op√ß√µes para a enquete",
                    },
                  },
                  required: ["question", "options"],
                  additionalProperties: false,
                },
                location: {
                  type: "object",
                  properties: {
                    latitude: {
                      type: "number",
                      description: "Latitude da localiza√ß√£o",
                    },
                    longitude: {
                      type: "number",
                      description: "Longitude da localiza√ß√£o",
                    },
                  },
                  required: ["latitude", "longitude"],
                  additionalProperties: false,
                },
              },
              required: ["type"],
              additionalProperties: false,
            },
          },
        },
        required: ["actions"],
        additionalProperties: false,
      }
  };

  beautifulLogger.aiGeneration("processing", "Enviando requisi√ß√£o para OpenAI...");

  const response = await LlmService.getInstance().callText(inputMessages, responseSchema)

  beautifulLogger.aiGeneration("cost", {
    "tokens entrada": response.usage?.prompt_tokens,
    "tokens sa√≠da": response.usage?.completion_tokens,
    "tokens total": response.usage?.total_tokens,
  });

  try {
    const parsedResponse: AIChatResponseType = AIChatResponseZod.parse(response.response);

    beautifulLogger.aiGeneration("response", {
      "quantidade de a√ß√µes": parsedResponse.actions.length,
      "tipos de a√ß√£o": parsedResponse.actions.map((a) => a.type).join(", "),
    });

    beautifulLogger.aiGeneration("complete", {
      "a√ß√µes processadas": parsedResponse.actions.length,
      "pronto para enviar": "sim",
    });

    return {
      actions: parsedResponse.actions
    };
  } catch (error) {
    console.error("Erro ao fazer parse da resposta JSON:", error);
    throw new Error("Resposta da IA n√£o est√° no formato JSON v√°lido");
  }
}
